{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380e3a63",
   "metadata": {},
   "source": [
    "# Goals\n",
    "My aim here is to create a wine recommendation system for a friend's web application. Presumably, the web application's database would already be populated with various wines and their characteristics.\n",
    "\n",
    "The idea would be for a user to sign up with the app, and slowly build out their rankings of various wines they've tried.\n",
    "\n",
    "At a certain point, the following model would be used to predict future user wine rankings based on the characteristics of wines they'd already have ranked.\n",
    "\n",
    "The following test uses an existing database of various wines, their characteristics, and simulated user rankings in order to determine the best type of learning model for the given circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f5c99cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3730220",
   "metadata": {},
   "source": [
    "# Importing Data\n",
    "I found a dataset containing wine characteristics that I'll use to simulate a database of various wines and their features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92811d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\n",
    "    'Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', \n",
    "    'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', \n",
    "    'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "    'OD280/OD315 of diluted wines', 'Proline'\n",
    "]\n",
    "\n",
    "path = '/Users/caseyfranco/Desktop/Data Science Resources/Wine Data/wine.data'\n",
    "df = pd.read_csv(path, header=None, names=column_names)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136320ff",
   "metadata": {},
   "source": [
    "# User Ranking Simulation\n",
    "Because I don't have access to these wines, it isn't feasible to try and replicate user rankings myself. Also, if I were to use randomly generated numbers for the user ranking column, this wouldn't accurately reflect a human having a particular taste for a certain type of wine.\n",
    "\n",
    "To try and get around these, I'll choose two columns at random, normalize them, create a \"taste score\" by summing the two, and then scale that score to a 1-10 scale to simulate a user rating.\n",
    "\n",
    "This should create a correlative relation between the user rankings and the wine features that the predictive models can try to identify.\n",
    "\n",
    "Lastly, I'll remove the normalized columns and the taste score from the training data.\n",
    "\n",
    "In reality, I wouldn't know which would be the most predictive categories but could use Feature Importance to determine which factors mattered to a person the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d73e7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>User_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>7.599563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>5.657262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>5.905169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>6.031853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  User_Rating  \n",
       "0             5.64  1.04                          3.92     1065     7.599563  \n",
       "1             4.38  1.05                          3.40     1050     5.657262  \n",
       "2             5.68  1.03                          3.17     1185     5.905169  \n",
       "3             7.80  0.86                          3.45     1480    10.000000  \n",
       "4             4.32  1.04                          2.93      735     6.031853  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new, normalized Alcohol and Phenols columns \n",
    "df['Alcohol_norm'] = (df['Alcohol'] - df['Alcohol'].min()) / (df['Alcohol'].max() - df['Alcohol'].min())\n",
    "df['Total_phenols_norm'] = (df['Total phenols'] - df['Total phenols'].min()) / (df['Total phenols'].max() - df['Total phenols'].min())\n",
    "\n",
    "# Compute a simple taste score based on these features\n",
    "df['Taste_Score'] = df[['Alcohol_norm', 'Total_phenols_norm']].sum(axis=1)\n",
    "\n",
    "# Scale the Taste_Score to a 1-10 scale for the User_Rating\n",
    "df['User_Rating'] = 1 + (df['Taste_Score'] - df['Taste_Score'].min()) * 9 / (df['Taste_Score'].max() - df['Taste_Score'].min())\n",
    "\n",
    "# Drop the normalization columns\n",
    "df.drop(['Alcohol_norm', 'Total_phenols_norm', 'Taste_Score'], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c775070",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "I'll try Simple Linear, Ridge, and Lasso Regressions as well as Random Forest to test their ability to identify patterns between a user's preferences and the characteristics of various wines in order to make predictions on whether or not a user might enjoy a given wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ad20741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Mean Squared Error: 0.00, R^2 Score: 1.00\n",
      "Ridge Regression - Mean Squared Error: 0.00, R^2 Score: 1.00\n",
      "Lasso Regression - Mean Squared Error: 1.24, R^2 Score: 0.68\n",
      "Random Forest Regression - Mean Squared Error: 0.07, R^2 Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X = df.drop('User_Rating', axis=1)  # Features\n",
    "y = df['User_Rating']  # Target variable\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Random Forest Regression': RandomForestRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    y_pred = model.predict(X_test)  # Predictions\n",
    "    \n",
    "    # Evaluation\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'{name} - Mean Squared Error: {mse:.2f}, R^2 Score: {r2:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "879e70f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - CV Mean Squared Error: 0.00, Std: 0.00\n",
      "Ridge Regression - CV Mean Squared Error: 0.00, Std: 0.00\n",
      "Lasso Regression - CV Mean Squared Error: 2.27, Std: 0.68\n",
      "Random Forest Regression - CV Mean Squared Error: 0.36, Std: 0.14\n"
     ]
    }
   ],
   "source": [
    "# It seems likely that I would use Random Forest, but I'll check the cross-validation scores to be sure\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Adjusted loop to include cross-validation\n",
    "for name, model in models.items():\n",
    "    # Perform 5-fold cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Convert scores to positive (because cross_val_score returns negative values for MSE to maximize the score)\n",
    "    cv_scores_positive = -cv_scores\n",
    "    \n",
    "    # Calculate the mean and standard deviation of the cross-validated scores\n",
    "    mean_cv_score = np.mean(cv_scores_positive)\n",
    "    std_cv_score = np.std(cv_scores_positive)\n",
    "    \n",
    "    print(f'{name} - CV Mean Squared Error: {mean_cv_score:.2f}, Std: {std_cv_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edbfcc1",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Based on the model results, it's likely that the Linear and Ridge regressions are overfitting due to the linear nature of the simulated user rankings. Lasso regression has an underwealming r squared score. \n",
    "\n",
    "Random Forest seems to be a good fit, however, it is important to note that I cannot confirm that until I create my own database and populate it with actual user scores.\n",
    "\n",
    "There's no computing for good taste!\n",
    "\n",
    "From here the model would be saved using Joblib and brought into Flask where it would be integrated with the web app.\n",
    "\n",
    "This program would also need to be fleshed out. Its functionality would lie in regularly cycling through unranked wines, testing them against the existing user preferences, recommending those that scored the highest predicted rankings, and regualrly retraining itself each time a user gave a new ranking or revised an old ranking. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
